<!DOCTYPE HTML>
<html>

<head><meta name="generator" content="Hexo 3.9.0">
	<link rel="bookmark" type="image/x-icon" href="/img/logo_miccall.jpg">
	<link rel="shortcut icon" href="/img/logo_miccall.jpg">
	
			    <title>
    
    </title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <link rel="stylesheet" href="/css/mic_main.css">
    <link rel="stylesheet" href="/css/dropdownMenu.css">
    <meta name="keywords" content="oreodu">
    
    	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	 
    <noscript>
        <link rel="stylesheet" href="/css/noscript.css">
    </noscript>
    <style type="text/css">
        body:before {
          content: ' ';
          position: fixed;
          top: 0;
          background: url('/img/bg.jpg') center 0 no-repeat;
          right: 0;
          bottom: 0;
          left: 0;
          background-size: cover; 
        }
    </style>

			    
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script async type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


    <script src="/js/jquery.min.js"></script>
    <script src="/js/jquery.scrollex.min.js"></script>
    <script src="/js/jquery.scrolly.min.js"></script>
    <script src="/js/skel.min.js"></script>
    <script src="/js/util.js"></script>
    <script src="/js/main.js"></script>
	
<link rel="stylesheet" href="/css/prism-base16-ateliersulphurpool.light.css" type="text/css"></head>
    
		
<!-- Layouts -->



<!--  代码渲染  -->
<link rel="stylesheet" href="/css/prism_coy.css">
<link rel="stylesheet" href="/css/typo.css">
<!-- 文章页 -->
<body class="is-loading">
    <!-- Wrapper 外包 s-->
    <div id="wrapper" class="fade-in">
        <!-- Intro 头部显示 s -->
        <!-- Intro 头部显示 e -->
        <!-- Header 头部logo start -->
        <header id="header">
    <a href="/" class="logo">Hello World</a>
</header>
        <!-- Nav 导航条 start -->
        <nav id="nav" class="special">
            <ul class="menu links">
			<!-- Homepage  主页  --> 
			<li>
	            <a href="/" rel="nofollow">Home</a>
	        </li>
			<!-- categories_name  分类   --> 
	        
	        <li class="active">
	            <a href="#s1">Classification</a>
	                    <ul class="submenu">
	                        <li>
	                        <a class="category-link" href="/categories/Algorithms/">Algorithms</a></li><li><a class="category-link" href="/categories/Data-Structure/">Data Structure</a></li><li><a class="category-link" href="/categories/Machine-Lerning/">Machine Lerning</a></li><li><a class="category-link" href="/categories/Programming/">Programming</a></li><li><a class="category-link" href="/categories/Start-with-me/">Start with me</a>
	                    </li></ul>
	        </li>
	        
	        <!-- archives  归档   --> 
	        
	        
		        <!-- Pages 自定义   -->
		        


            </ul>
            <!-- icons 图标   -->
			<ul class="icons">
                    
                    <li>
                        <a title="github" href="https://github.com/OreoDu" target="_blank" rel="noopener">
                            <i class="icon fa fa-github"></i>
                        </a>
                    </li>
                    
			</ul>
</nav>

        <div id="main">
            <div class="post_page_title_img" style="height: 25rem;background-image: url(http://q9c32mgkt.bkt.clouddn.com/static/images/sha-pur.jpg);background-position: center; background-repeat:no-repeat; background-size:cover;-moz-background-size:cover;overflow:hidden;">
                <a href="#" style="padding: 4rem 4rem 2rem 4rem ;"><h2>Neural Networks</h2></a>
            </div>
            <!-- Post -->
            <div class="typo" style="padding: 3rem;">
                <h1 id="Neural-Networks"><a href="#Neural-Networks" class="headerlink" title="Neural Networks"></a>Neural Networks</h1><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>(概略图)</p>
<p><strong>· materials:</strong></p>
<p>  · Wikipedia</p>
<p>  · Machine Learning </p>
<h2 id="1-Neural-Network-or-MLP"><a href="#1-Neural-Network-or-MLP" class="headerlink" title="1. Neural Network or MLP"></a>1. Neural Network or MLP</h2><p><img src="https://i.loli.net/2020/06/22/DvejB2L6YuKFCcO.png" alt="mlp"></p>
<h3 id="Cost-Function-regularized"><a href="#Cost-Function-regularized" class="headerlink" title="Cost Function (regularized)"></a>Cost Function (regularized)</h3><p><strong>·</strong> L = total number of layers in the network</p>
<p><strong>·</strong> $ s_l $ = number of units (not counting bias unit) in layer l</p>
<p><strong>·</strong> K = number of output units/classes</p>
<p><strong>·</strong> Activation Function</p>
<p>​    <strong>1)</strong> Sigmoid Function:  $ h_\theta (x) = g(\theta^T x) = \dfrac{1}{1 + e^{- \theta^T x}} $</p>
<p>​        Avoid overflow: </p>
<p>​       $  \dfrac{1}{1 + e^{- \theta^T x}} = \ frac {tan(\frac{x}{2}) + 1}{2}$</p>
<p>​       $ tanx = \frac{e^x - e^{-x}}{e^x + e^{-x}}  =  \frac{e^{2x} - 1 }{e^{2x} + 1} = \frac{1 - e^{-2x} }{1 + e^{-2x} }$</p>
<p>​    <strong>2)</strong> ReLU Function: $  h(x)= x ( x &gt; 0 )  or  0 ( x \geq 0 )  $</p>
<p>​    <strong>3)</strong> Softmax Function:  $ h(x)_ k = \frac{exp(a_k)}{\sum_ {i=1}^K exp(a_i)} $</p>
<p>​        Avoid overflow: (c can be the - max(a))</p>
<p>​        $ h(x)_ k = \frac{exp(a_k + c)}{\sum_ {i=1}^K exp(a_i + c)} $ </p>
<p>The activation Function of the output layer depend on the specific problems. </p>
<p>For example: Binary classification — sigmoid function, Multiple Classification — softmax function, Regression — identity function</p>
<p>$ J(\Theta) = - \frac{1}{m} \sum_ {i=1}^m \sum_ {k=1}^K \left[y^{(i)}_ k \log ((h_ \Theta (x^{(i)}))_ k) + (1 - y^{(i)}_ k)\log (1 - (h_ \Theta(x^{(i)}))_ k)\right] + \frac{\lambda}{2m}\sum_ {l=1}^{L-1} \sum_ {i=1}^{s_l} \sum_ {j=1}^{s_ {l+1}} ( \Theta_{j,i}^{(l)})^2 $</p>
<h3 id="Backpropagation-Algorithm"><a href="#Backpropagation-Algorithm" class="headerlink" title="Backpropagation Algorithm"></a>Backpropagation Algorithm</h3><p><strong>·</strong> Given training set $ { (x^{(1)}, y^{(1)}) … (x^{(m)}, y^{(m)})} $</p>
<p><strong>·</strong> Set $ \Delta^{(l)}_{i,j} := 0$ for all (l,i,j)</p>
<p><strong>·</strong> For training example t =1 to m:</p>
<p>​     <strong>1)</strong> $ a^{(1)} = x $</p>
<p>​     <strong>2)</strong> Perform forward propagation to compute $a^{(l)}$ for l=2,3,…,L</p>
<p>​           $ z^{(l)} = \Theta^{(l-1)} a^{(l-1)} $</p>
<p>​           $ a^{(l)} = g(z^{(l)}) $</p>
<p>​     <strong>3)</strong> Using $y^{(t)}$, compute $\delta^{(L)} = a^{(L)} - y^{(t)} $</p>
<p>​     <strong>4)</strong> Compute $ \delta^{(L-1)}, \delta^{(L-2)},\dots,\delta^{(2)} $ </p>
<p>using $\delta^{(l)} = ((\Theta^{(l)})^T \delta^{(l+1)})  .* g^{′}(z^{(l)}) ),  ( g^{′}(z^{(l)})=a^{(l)} .* (1−a^{(l)}) ) $</p>
<p>​     <strong>5)</strong> $\Delta^{(l)}_ {i,j} := \Delta^{(l)}_ {i,j} + a^{(l)}_ j \delta^{(l+1)}_ j $ or with vectorization, $\Delta^{(l)} := \Delta^{(l)} + \delta^{(l+1)} (a^{(l)})^T $</p>
<p>​     Hence we update our new $\Delta$ matrix. ($\frac{∂J(\Theta)}{∂\Theta^{(l)}_ {i,j}} = D^{(l)}_ {i,j}$)</p>
<p>​     $ D^{(l)}_ {i,j} =  \frac{1}{m} \Delta^{(l)}_ {i,j}, $ if j = 0</p>
<p>​     $D^{(l)}_ {i,j} =  \frac{1}{m}(\Delta^{(l)}_ {i,j} + \lambda \Theta^{(l)}_ {i,j}),$ if j≠0</p>
<h3 id="Gradient-Checking"><a href="#Gradient-Checking" class="headerlink" title="Gradient Checking"></a>Gradient Checking</h3><p>Gradient checking will assure that our backpropagation works as intended. </p>
<p>We can approximate the derivative of our cost function with: ($ ϵ =10^{−4} $)</p>
<p>$ \frac{∂J(\Theta)}{∂\Theta_ {j}} = \frac{J(\Theta_1 ,…, \Theta_j + ϵ ,…, \Theta_n) - J(\Theta_1 ,…, \Theta_j - ϵ ,…, \Theta_n)}{2ϵ}  $</p>
<h3 id="Main-Steps"><a href="#Main-Steps" class="headerlink" title="Main Steps"></a>Main Steps</h3><p>First, pick a network architecture.</p>
<p>​    · Number of input units = dimension of features $x^{(i)}$</p>
<p>​    · Number of output units = number of classes</p>
<p>​    · Number of hidden units per layer = usually more the better (must balance with cost of computation as it increases with more hidden units)</p>
<p>Next, training a Neural Network.</p>
<p>​    · Randomly initialize the weights</p>
<p>​    · Implement forward propagation to get $ h_\Theta(x^{(i)}) $ for any $ x^{(i)} $</p>
<p>​    · Implement the cost function</p>
<p>​    · Implement backpropagation to compute partial derivatives</p>
<p>​    · Use gradient checking to confirm that your backpropagation works. Then disable gradient checking.</p>
<p>​    · Use gradient descent or a built-in optimization function to minimize the cost function with the weights in theta.</p>

            </div>

            <!-- Post Comments -->
            
    <!-- 使用 valine -->
<div id="comment">
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
<script>
    new Valine({
        el: '#comment' ,
        notify: false,
        verify: false,
        app_id: 'pi6wgQQwDcdAXXPAYDhLTXAM-gzGzoHsz',
        app_key: 'apbjMMH4cLAjmeGJWDdGGE01',
        placeholder: 'Please leave your footprints~~',
        pageSize: '10',
        avatar: 'retro',
        avatar_cdn: ''
    });
</script>
</div>
<style>
   #comment{
        padding: 2pc;
    }
</style>


        </div>
        <!-- Copyright 版权 start -->
                <div id="copyright">
            <ul>
                <li>&copy;Powered By <a href="https://hexo.io/zh-cn/" style="border-bottom: none;">hexo</a></li>
                <li>Design: <a href="http://miccall.tech " style="border-bottom: none;">miccall</a></li>
            </ul>
            
                <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
			
        </div>
    </div>
</body>



 	
</html>
