{"title":"Basis & Regression & Classification","date":"2020-05-01T07:45:00.000Z","date_formatted":{"ll":"May 1, 2020","L":"05/01/2020","MM-DD":"05-01"},"link":"2020/20200501-Machine-Learning-Basis","comments":true,"tags":["Machine Lesarning Basis"],"categories":["Machine Lerning"],"updated":"2020-10-03T18:15:18.345Z","content":"<h1 id=\"basis-&amp;-regression-&amp;-classification\">Basis &amp; Regression &amp; Classification<a title=\"#basis-&amp;-regression-&amp;-classification\" href=\"#basis-&amp;-regression-&amp;-classification\"></a></h1>\n<h3 id=\"overview\">Overview<a title=\"#overview\" href=\"#overview\"></a></h3>\n<p>(概略图)</p>\n<p><strong>· materials:</strong></p>\n<p>· Wikipedia</p>\n<p>· Machine Learning</p>\n<h2 id=\"1.-intro\">1. Intro<a title=\"#1.-intro\" href=\"#1.-intro\"></a></h2>\n<p>Tom Mitchell provides a more modern definition: “A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.”</p>\n<h4 id=\"·-supervised-learning\">· Supervised Learning<a title=\"#·-supervised-learning\" href=\"#·-supervised-learning\"></a></h4>\n<p>In supervised learning, we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output.</p>\n<p>Supervised learning problems are categorized into <strong>“regression”</strong> and **“classification” ** problems. In a regression problem, we are trying to predict results within a continuous output, meaning that we are trying to map input variables to some continuous function. In a classification problem, we are instead trying to predict results in a discrete output. In other words, we are trying to map input variables into discrete categories.</p>\n<h4 id=\"·-unsupervised-learning\">· Unsupervised Learning<a title=\"#·-unsupervised-learning\" href=\"#·-unsupervised-learning\"></a></h4>\n<p>Unsupervised learning allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don’t necessarily know the effect of the variables.</p>\n<p>We can derive this structure by <strong>clustering</strong> the data based on relationships among the variables in the data.</p>\n<p>With unsupervised learning there is no feedback based on the prediction results.</p>\n<h4 id=\"·-model\">· Model<a title=\"#·-model\" href=\"#·-model\"></a></h4>\n<p>To describe the supervised learning problem slightly more formally, our goal is, given a training set, to learn the hypothesis function h : X → Y so that h(x) is a “good” predictor for the corresponding value of y.</p>\n<p>Inout : X</p>\n<p>Output: Y</p>\n<p>Hypothesis function: h</p>\n<p>Cost function : J</p>\n<p>Objective function: minimize (J)</p>\n<h2 id=\"2.-regression\">2. Regression<a title=\"#2.-regression\" href=\"#2.-regression\"></a></h2>\n<h3 id=\"linear-regression\">Linear Regression<a title=\"#linear-regression\" href=\"#linear-regression\"></a></h3>\n<p>$ h_\\theta (x) =  \\theta_1 x + \\theta_0 $</p>\n<h4 id=\"cost-function\">Cost Function<a title=\"#cost-function\" href=\"#cost-function\"></a></h4>\n<p>We can measure the accuracy of our hypothesis function by using a <strong>cost function</strong>.</p>\n<p><strong>Mean Squared Error</strong></p>\n<p>$  J(\\theta_0, \\theta_1) =  \\frac{1}{2m} \\sum^{m}_ {i=1} {( h_ \\theta(x^{(i)}) - y^{(i)} )^2} $</p>\n<p>$ J(\\theta_0, \\theta_1) $ can be ploted by a contour figure.</p>\n<h4 id=\"gradient-descent-(minizining-the-cost-function-j)\">Gradient descent (minizining the cost function J)<a title=\"#gradient-descent-(minizining-the-cost-function-j)\" href=\"#gradient-descent-(minizining-the-cost-function-j)\"></a></h4>\n<p>$ \\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_j^{(i)} $</p>\n<p>(Update $\\theta_j$ simultaneously)</p>\n<p>learning rate: <strong>α</strong></p>\n<p>we should adjust our parameter <em>α</em> to ensure that the gradient descent algorithm converges in a reasonable time. Failure to converge or too much time to obtain the minimum value imply that our step size is wrong.</p>\n<p>The method looks at every example in the entire training set on every step, and is called <strong>batch gradient descent</strong></p>\n<p><u><a href=\"https://medium.com/@rohitpandey576/why-does-gradient-descent-work-128713588136\" target=\"_blank\">Why does gradient descent work?</a></u></p>\n<h3 id=\"multivariate-linear-regression\">Multivariate Linear Regression<a title=\"#multivariate-linear-regression\" href=\"#multivariate-linear-regression\"></a></h3>\n<p>Linear regression with multiple variables.</p>\n<p>$ h_\\theta (x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_3 + \\cdots + \\theta_n x_n $</p>\n<p>$ h_\\theta(x) =\\begin{bmatrix}\\theta_0 \\hspace{2em} \\theta_1 \\hspace{2em} … \\hspace{2em} \\theta_n\\end{bmatrix}\\begin{bmatrix}x_0 \\newline x_1 \\newline \\vdots \\newline x_n\\end{bmatrix}= \\theta^T X $</p>\n<p>$ x_{0}^{(i)} =1 \\text{ for } (i\\in { 1,\\dots, m } ) $</p>\n<p>$  J(\\theta) =  \\frac{1}{2m} \\sum^{m}_ {i=1} {( h_ \\theta(x^{(i)}) - y^{(i)} )^2} $</p>\n<h4 id=\"feature-scaling\">Feature Scaling<a title=\"#feature-scaling\" href=\"#feature-scaling\"></a></h4>\n<p>We can speed up gradient descent by having each of our input values in roughly the same range. This is because θ will descend quickly on small ranges and slowly on large ranges, and so will oscillate inefficiently down to the optimum when the variables are very uneven.</p>\n<p>Two techniques to help with this are <strong>feature scaling</strong> and <strong>mean normalization</strong>.</p>\n<p>feature scaling : $ x_i = \\frac{x_i}{s_i} $</p>\n<p>mean normalization : $ x_i = \\frac{x_i - \\mu_i}{s_i} $</p>\n<p>($ s_i $:  standard deviation , $ \\mu_i $: average)</p>\n<h4 id=\"gradient-descent\">Gradient descent<a title=\"#gradient-descent\" href=\"#gradient-descent\"></a></h4>\n<p>$ \\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_j^{(i)} $</p>\n<p><strong>Debugging gradient descent.</strong></p>\n<p>Make a plot with <em>number of iterations</em> and cost function J(θ).  It has been proven that if learning rate α is sufficiently small, then J(θ) will decrease on every iteration.</p>\n<p>If <em>α</em> is too small: slow convergence.</p>\n<p>If <em>α</em> is too large: may not decrease on every iteration and thus may not converge.</p>\n<p>(Try like this: … 0.001 … 0.01 … 0.1 … 1)</p>\n<h4 id=\"normal-equation\">Normal Equation<a title=\"#normal-equation\" href=\"#normal-equation\"></a></h4>\n<p>Normal Equation is a second way of minimizing J.</p>\n<p>In the “Normal Equation” method, we will minimize J by explicitly taking its derivatives with respect to the θj ’s, and setting them to zero. This allows us to find the optimum theta without iteration.</p>\n<p>$ \\theta =( X_T  X)^{-1}X_TY  $</p>\n<div class=\"φcy\"><div class=\"φda\"><table><thead>\n<tr>\n<th>Gradient Descent</th>\n<th><strong>Normal Equation</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Need to choose alpha</td>\n<td>No need to choose alpha</td>\n</tr>\n<tr>\n<td>Needs many iterations</td>\n<td>No need to iterate</td>\n</tr>\n<tr>\n<td>$ O(kn^2)$</td>\n<td>$ O(n^3)$, need to calculate inverse of $ X^TX $</td>\n</tr>\n<tr>\n<td>Works well when n is large</td>\n<td>Slow if n is very large</td>\n</tr>\n</tbody>\n</table></div></div><p>If $ X^TX $ is <strong>noninvertible,</strong> the common causes might be having :</p>\n<p><strong>·</strong> Redundant features, where two features are very closely related (i.e. they are linearly dependent)<br>\n<strong>·</strong> Too many features (e.g. m ≤ n). In this case, delete some features or use “regularization”.</p>\n<h3 id=\"polynomial-regression\">Polynomial Regression<a title=\"#polynomial-regression\" href=\"#polynomial-regression\"></a></h3>\n<p>We can <strong>change the behavior or curve</strong> of our hypothesis function by making it a quadratic, cubic or square root function (or any other form).</p>\n<p>e.g.  $ h_\\theta (x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3 $</p>\n<p>( if you choose your features this way then feature scaling becomes very important. $ 10^3 = 1000 $)</p>\n<p>Feature choosing: We can <strong>combine</strong> multiple features into one.</p>\n<h2 id=\"3.-classification(logistic-regression)\">3. Classification(Logistic regression)<a title=\"#3.-classification(logistic-regression)\" href=\"#3.-classification(logistic-regression)\"></a></h2>\n<h3 id=\"binary-classification\">Binary classification<a title=\"#binary-classification\" href=\"#binary-classification\"></a></h3>\n<h4 id=\"activiation-fuction\">Activiation Fuction<a title=\"#activiation-fuction\" href=\"#activiation-fuction\"></a></h4>\n<p>The activation Function of the output layer depend on the specific problems.</p>\n<p>For example: Binary classification — sigmoid function, Multiple Classification — softmax function, Regression — identity function</p>\n<p><strong>· Sigmoid Function</strong> (maps any real number to the (0, 1) interval)</p>\n<p>$ h_\\theta (x) = g(\\theta^T x) = \\dfrac{1}{1 + e^{- \\theta^T x}} $</p>\n<p>$ h_\\theta(x) = P(y=1 | x ; \\theta) = 1 - P(y=0 | x ; \\theta) $</p>\n<p><strong>Decision Boundary</strong> (The property of the Hypothesis function)</p>\n<p>$ h_\\theta(x) = g(\\theta^T x) \\geq 0.5     when \\theta^T x \\geq 0 $</p>\n<p>Non-linear decision boundary : $ \\theta^T x = \\theta_0 + \\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3 $</p>\n<h4 id=\"cost-function-1\">Cost function<a title=\"#cost-function-1\" href=\"#cost-function-1\"></a></h4>\n<p>We cannot use the same cost function that we use for linear regression because the Logistic Function will not be a convex function, causing many local optima.</p>\n<p><strong>Cross Entropy Error</strong></p>\n<p>$ J(\\theta) = \\dfrac{1}{m} \\sum_ {i=1}^m \\mathrm{Cost}(h_\\theta(x^{(i)}),y^{(i)}) $</p>\n<p>$ Cost (h_ \\theta(x^{(i)}),y^{(i)}) = -y^{(i)} \\log(h_ \\theta(x^{(i)}))  - (1- y^{(i)}) \\log(1-h_ \\theta(x^{(i)}))  $</p>\n<p>$ \\mathrm{Cost}(h_\\theta(x),y) = 0 \\text{ ,if } h_\\theta(x) = y $</p>\n<p>$ \\mathrm{Cost}(h_ \\theta(x),y) \\rightarrow \\infty \\text{ ,if } y=0 \\mathrm{and}  h_\\theta(x) \\rightarrow 1 $</p>\n<p>$ \\mathrm{Cost}(h_ \\theta(x),y) \\rightarrow \\infty \\text{ ,if } y=1  \\mathrm{and}  h_\\theta(x) \\rightarrow 0 $</p>\n<p>When $ h_ \\theta(x^{(i)}) $ become so small, the value of log will become negative infinity. So in order to avoid such situation, we can add a small value to the $ h_ \\theta(x^{(i)}) $, usually it can be 1e-7.</p>\n<h4 id=\"gradient-descent-1\">Gradient descent<a title=\"#gradient-descent-1\" href=\"#gradient-descent-1\"></a></h4>\n<p>$ \\theta_j := \\theta_j - \\frac{\\alpha}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)} $</p>\n<p><strong>Advanced Optimization</strong></p>\n<p>“Conjugate gradient”, “BFGS”, and “L-BFGS” are more sophisticated, faster ways to optimize θ and also no need to manually pick $ \\alpha $ which can be used instead of gradient descent.</p>\n<h3 id=\"multiple-classification\">Multiple Classification<a title=\"#multiple-classification\" href=\"#multiple-classification\"></a></h3>\n<p><strong>One-vs-all</strong></p>\n<p>$ h_\\theta^{(i)}(x) = P(y = i | x ; \\theta)   y \\in \\lbrace0, 1 … n\\rbrace$</p>\n<p>$ \\mathrm{prediction} = \\max_i( h_\\theta ^{(i)}(x) ) $</p>\n","prev":{"title":"Neural Networks","link":"2020/20200516-Neural-Networks"},"next":{"title":"Linear List","link":"2020/20200425-Linear-List"},"plink":"https://oreodu.github.io/2020/20200501-Machine-Learning-Basis/","toc":[{"id":"basis-&amp;-regression-&amp;-classification","title":"Basis &amp; Regression &amp; Classification","index":"1","children":[{"id":"1.-intro","title":"1. Intro","index":"1.1"},{"id":"2.-regression","title":"2. Regression","index":"1.2"},{"id":"3.-classification(logistic-regression)","title":"3. Classification(Logistic regression)","index":"1.3"}]}],"reward":true,"copyright":{"author":"Oreo Du","link":"<a href=\"https://oreodu.github.io/2020/20200501-Machine-Learning-Basis/\" title=\"Basis & Regression & Classification\">https://oreodu.github.io/2020/20200501-Machine-Learning-Basis/</a>","license":"Attribution-NonCommercial-NoDerivatives 4.0 International (<a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\" rel=\"external nofollow noopener\" target=\"_blank\">CC BY-NC-ND 4.0</a>)"}}