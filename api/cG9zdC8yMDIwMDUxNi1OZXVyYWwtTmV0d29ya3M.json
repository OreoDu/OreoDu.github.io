{"title":"Neural Networks","date":"2020-05-16T07:45:00.000Z","thumbnail":"https://i.loli.net/2020/09/09/b8j9raHsZBgGdLu.jpg","slug":"20200516-Neural-Networks","tags":["Neural Networks"],"categories":["Deep Learning"],"updated":"2020-09-09T09:11:51.046Z","content":"<h1 id=\"Neural-Networks\">Neural Networks<a href=\"post/20200516-Neural-Networks#Neural-Networks\"></a></h1><h3 id=\"Overview\">Overview<a href=\"post/20200516-Neural-Networks#Overview\"></a></h3><p>(概略图)</p>\n<p><strong>· materials:</strong></p>\n<p>  · Wikipedia</p>\n<p>  · Machine Learning </p>\n<h3 id=\"Why-Neural-Networks\">Why Neural Networks?<a href=\"post/20200516-Neural-Networks#Why-Neural-Networks\"></a></h3><h4 id=\"·-Decision-Boundary\">· Decision Boundary<a href=\"post/20200516-Neural-Networks#·-Decision-Boundary\"></a></h4><p>Every Machine Learning algorithm learns the mapping from an input to output. </p>\n<p>In the case of classification problems, a decision boundary helps us in determining whether a given data point belongs to a certain class. Traditional machine learning algoritms cannot learn decision boundaries for nonlinear data.  However, Neural Network is capable of learning any nonlinear function.</p>\n<p>Also, those algorithms are not capable of learning all the functions.</p>\n<h4 id=\"·-Feature-engineering\">· Feature engineering<a href=\"post/20200516-Neural-Networks#·-Feature-engineering\"></a></h4><p>In machine learning, we have to do feature  extraction and feature selection before we train the model. Feature engineering is a key step in the model building process. However, in deep Learning, we can automate the process of feature engineering.</p>\n<h2 id=\"Feed-Forward-Neural-network-Multilayer-Perceptron\">Feed-Forward Neural network (Multilayer Perceptron)<a href=\"post/20200516-Neural-Networks#Feed-Forward-Neural-network-Multilayer-Perceptron\"></a></h2><img src=\"https://i.loli.net/2020/06/22/DvejB2L6YuKFCcO.png\" alt=\"mlp\" style=\"zoom: 50%;\">\n\n\n\n<h3 id=\"Cost-Function-regularized\">Cost Function (regularized)<a href=\"post/20200516-Neural-Networks#Cost-Function-regularized\"></a></h3><p><strong>·</strong> L = total number of layers in the network</p>\n<p><strong>·</strong> $ s_l $ = number of units (not counting bias unit) in layer l</p>\n<p><strong>·</strong> K = number of output units/classes</p>\n<p>$ J(\\Theta) = - \\frac{1}{m} \\sum_ {i=1}^m \\sum_ {k=1}^K \\left[y^{(i)}_ k \\log ((h_ \\Theta (x^{(i)}))_ k) + (1 - y^{(i)}_ k)\\log (1 - (h_ \\Theta(x^{(i)}))_ k)\\right] + \\frac{\\lambda}{2m}\\sum_ {l=1}^{L-1} \\sum_ {i=1}^{s_l} \\sum_ {j=1}^{s_ {l+1}} ( \\Theta_{j,i}^{(l)})^2 $</p>\n<h3 id=\"Backpropagation-Algorithm\">Backpropagation Algorithm<a href=\"post/20200516-Neural-Networks#Backpropagation-Algorithm\"></a></h3><p><strong>·</strong> Given training set $ { (x^{(1)}, y^{(1)}) … (x^{(m)}, y^{(m)})} $</p>\n<p><strong>·</strong> Set $ \\Delta^{(l)}_{i,j} := 0$ for all (l,i,j)</p>\n<p><strong>·</strong> For training example t =1 to m:</p>\n<p>​     <strong>1)</strong> $ a^{(1)} = x $</p>\n<p>​     <strong>2)</strong> Perform forward propagation to compute $a^{(l)}$ for l=2,3,…,L</p>\n<p>​           $ z^{(l)} = \\Theta^{(l-1)} a^{(l-1)} $</p>\n<p>​           $ a^{(l)} = g(z^{(l)}) $</p>\n<p>​     <strong>3)</strong> Using $y^{(t)}$, compute $\\delta^{(L)} = a^{(L)} - y^{(t)} $</p>\n<p>​     <strong>4)</strong> Compute $ \\delta^{(L-1)}, \\delta^{(L-2)},\\dots,\\delta^{(2)} $ </p>\n<p>using $\\delta^{(l)} = ((\\Theta^{(l)})^T \\delta^{(l+1)})  .* g^{′}(z^{(l)}) ),  ( g^{′}(z^{(l)})=a^{(l)} .* (1−a^{(l)}) ) $</p>\n<p>​     <strong>5)</strong> $\\Delta^{(l)}_ {i,j} := \\Delta^{(l)}_ {i,j} + a^{(l)}_ j \\delta^{(l+1)}_ j $ or with vectorization, $\\Delta^{(l)} := \\Delta^{(l)} + \\delta^{(l+1)} (a^{(l)})^T $</p>\n<p>​     Hence we update our new $\\Delta$ matrix. ($\\frac{∂J(\\Theta)}{∂\\Theta^{(l)}_ {i,j}} = D^{(l)}_ {i,j}$)</p>\n<p>​     $ D^{(l)}_ {i,j} =  \\frac{1}{m} \\Delta^{(l)}_ {i,j}, $ if j = 0</p>\n<p>​     $D^{(l)}_ {i,j} =  \\frac{1}{m}(\\Delta^{(l)}_ {i,j} + \\lambda \\Theta^{(l)}_ {i,j}),$ if j≠0</p>\n<p>In the actual programming implementation, we can separate back propagation through layers. </p>\n<p><u><a href=\"https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/common/layers.py\" target=\"_blank\" rel=\"noopener\">See  more details</a></u></p>\n<h3 id=\"Gradient-Checking\">Gradient Checking<a href=\"post/20200516-Neural-Networks#Gradient-Checking\"></a></h3><p>Gradient checking will assure that our backpropagation works as intended. </p>\n<p>We can approximate the derivative of our cost function with: ($ ϵ =10^{−4} $)</p>\n<p>$ \\frac{∂J(\\Theta)}{∂\\Theta_ {j}} = \\frac{J(\\Theta_1 ,…, \\Theta_j + ϵ ,…, \\Theta_n) - J(\\Theta_1 ,…, \\Theta_j - ϵ ,…, \\Theta_n)}{2ϵ}  $</p>\n<h3 id=\"Activation-Function\">Activation Function<a href=\"post/20200516-Neural-Networks#Activation-Function\"></a></h3><p>Activation functions introduce non-linearity to the model which allows it to learn complex functional mappings between the inputs and response variables. There are quite a few different activation functions like sigmoid, tanh, RelU, Leaky RelU, etc.</p>\n<p><u><a href=\"https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/\" target=\"_blank\" rel=\"noopener\">See  more details</a></u></p>\n<h4 id=\"Sigmoid-Function\">Sigmoid Function:<a href=\"post/20200516-Neural-Networks#Sigmoid-Function\"></a></h4><p>$ h_\\theta (x) = g(\\theta^T x) = \\dfrac{1}{1 + e^{- \\theta^T x}} $</p>\n<p>Avoid overflow: </p>\n<p>$  \\dfrac{1}{1 + e^{- \\theta^T x}} = \\frac{1}{2} (tan(\\frac{x}{2}) + 1)$</p>\n<p>$ tanx = \\frac{e^x - e^{-x}}{e^x + e^{-x}}  =  \\frac{e^{2x} - 1 }{e^{2x} + 1} = \\frac{1 - e^{-2x} }{1 + e^{-2x} }$</p>\n<h4 id=\"ReLU-Function（Rectified-Linear-Unit）\">ReLU Function（Rectified Linear Unit）:<a href=\"post/20200516-Neural-Networks#ReLU-Function（Rectified-Linear-Unit）\"></a></h4><p>$  h(x)= x ( x &gt; 0 )  or  0   ( x \\leq 0 )  $</p>\n<h4 id=\"Softmax-Function\">Softmax Function:<a href=\"post/20200516-Neural-Networks#Softmax-Function\"></a></h4><p>$ h(x)_ k = \\frac{exp(a_k)}{\\sum_ {i=1}^K exp(a_i)} $</p>\n<p>Avoid overflow: (c can be the - max(a))</p>\n<p>$ h(x)_ k = \\frac{exp(a_k + c)}{\\sum_ {i=1}^K exp(a_i + c)} $ </p>\n<p>The activation Function of the output layer depend on the specific problems. </p>\n<p>For example: Binary classification — sigmoid function, Multiple Classification — softmax function, Regression — identity function</p>\n<h3 id=\"Optimization-Function\">Optimization Function<a href=\"post/20200516-Neural-Networks#Optimization-Function\"></a></h3><p><u><a href=\"https://towardsdatascience.com/why-gradient-descent-isnt-enough-a-comprehensive-introduction-to-optimization-algorithms-in-59670fd5c096\" target=\"_blank\" rel=\"noopener\">See  more details</a></u></p>\n<h4 id=\"Gradient-Descent\">Gradient Descent:<a href=\"post/20200516-Neural-Networks#Gradient-Descent\"></a></h4><p>$ \\Theta^{(l)}_ {i,j} = \\Theta^{(l)}_ {i,j} - \\eta \\frac{∂J(\\Theta)}{∂\\Theta^{(l)}_ {i,j}} $</p>\n<p><strong>Standard Gradient descent</strong> updates the <em>parameters</em> only after each epoch.</p>\n<p><strong>Stochastic gradient descent</strong> updates the <em>parameters</em> for <em>each observation</em> which leads to more number of updates<em>.</em> </p>\n<p><strong>Mini-batch Gradient descent</strong> updates the parameters for a finite number of observations.</p>\n<h4 id=\"Momentum-based-Gradient-Descent\">Momentum-based Gradient Descent<a href=\"post/20200516-Neural-Networks#Momentum-based-Gradient-Descent\"></a></h4><p>$ v^{(l)}_ {i,j}  =  \\alpha v^{(l)}_ {i,j}  - \\eta \\frac{∂J(\\Theta)}{∂\\Theta^{(l)}_ {i,j}} $</p>\n<p>$ \\Theta^{(l)}_ {i,j} = \\Theta^{(l)}_ {i,j} + v^{(l)}_ {i,j}  $</p>\n<p> Momentum-based gradient descent remembers the update $v$ at each iteration, and determines the next update as a linear combination of the gradient and the previous update. Unlike in stochastic gradient descent, it tends to keep traveling in the same direction, preventing oscillations. </p>\n<p>(Extension: Nesterov accelerated Gradient Descent)</p>\n<h4 id=\"Adagrad\">Adagrad<a href=\"post/20200516-Neural-Networks#Adagrad\"></a></h4><p>$ h^{(l)}_ {i,j}  = h^{(l)}_ {i,j} +  ( \\frac{∂J(\\Theta)}{∂\\Theta^{(l)}_ {i,j}} )^2 $</p>\n<p>$ \\Theta^{(l)}_ {i,j} = \\Theta^{(l)}_ {i,j} + \\eta \\frac{1}{\\sqrt{h^{(l)}_ {i,j} } + \\epsilon}  \\frac{∂J(\\Theta)}{∂\\Theta^{(l)}_ {i,j}} $</p>\n<p>It adopts the learning rate(η) based on the <strong>sparsity</strong> of features. So the parameters with small updates(sparse features) have high <em>learning rate</em> whereas the parameters with large  updates(dense features) have low <em>learning rate</em>. Therefore adagrad uses a different <em>learning rate</em> for each <em>parameter.</em></p>\n<p>(Extension: RMSProp)</p>\n<h4 id=\"Adam-Adaptive-Moment-Estimation\">Adam(Adaptive Moment Estimation)<a href=\"post/20200516-Neural-Networks#Adam-Adaptive-Moment-Estimation\"></a></h4><p>Adam algorithm introduces the concept of adaptive momentum along with adaptive learning rate. Adam is a combined form of Momentum-based GD and RMSProp.</p>\n<img src=\"https://i.loli.net/2020/06/25/3eEICUzJWN5xLQA.png\" alt=\"adm\" style=\"zoom:50%;\">\n\n\n\n<h3 id=\"Initialize-the-weights\">Initialize the weights<a href=\"post/20200516-Neural-Networks#Initialize-the-weights\"></a></h3><p><u><a href=\"https://towardsdatascience.com/weight-initialization-techniques-in-neural-networks-26c649eb3b78\" target=\"_blank\" rel=\"noopener\">See  more details</a></u></p>\n<h4 id=\"Zero-initialization-and-Random-initialization\">Zero initialization and Random initialization<a href=\"post/20200516-Neural-Networks#Zero-initialization-and-Random-initialization\"></a></h4><p>In general practice biases are initialized with 0 and weights are initialized with random numbers.</p>\n<p>Usually, we can not initialize weight with the same values, high values or very low values. Otherwize, weight uniformity will happen or the gradients may vanish or explode quickly.</p>\n<h4 id=\"Xavier-initialization\">Xavier initialization<a href=\"post/20200516-Neural-Networks#Xavier-initialization\"></a></h4><p>It is mostly used for tanh() or sigmoid() activation function.</p>\n<img src=\"https://i.loli.net/2020/06/25/AKQsCMUT6bedVtw.png\" alt=\"Xavier\" style=\"zoom: 50%;\">\n\n<img src=\"https://i.loli.net/2020/06/25/6QfRzvADObthNVy.png\" alt=\"Xavier1\" style=\"zoom: 50%;\">\n\n\n\n<h4 id=\"He-initialization\">He initialization<a href=\"post/20200516-Neural-Networks#He-initialization\"></a></h4><p>It is mostly used for ReLU() activation function.</p>\n<img src=\"https://i.loli.net/2020/06/25/x5W4gyvkenXT3zf.png\" alt=\"he\" style=\"zoom: 50%;\">\n\n\n\n<h3 id=\"Batch-Normalization\">Batch Normalization<a href=\"post/20200516-Neural-Networks#Batch-Normalization\"></a></h3><p>Apart from the input layer, we can also normalize the hiden layer by adjusting and scaling the input. Batch normalization reduces the amount by what the hidden unit values shift around (covariance shift) and allows each layer of a network to learn by itself a little bit more independently of other layers. Also, it reduces overfitting because it has a slight regularization effects. Similar to dropout, it adds some noise to each hidden layer’s activations.</p>\n<p>See  more details <u><a href=\"https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html\" target=\"_blank\" rel=\"noopener\">here</a></u> and <u><a href=\"https://towardsdatascience.com/batch-normalization-in-neural-networks-1ac91516821c\" target=\"_blank\" rel=\"noopener\">here</a></u></p>\n<img src=\"https://i.loli.net/2020/06/25/IGgC3xaJDARne75.png\" alt=\"BN\" style=\"zoom:50%;\">\n\n\n\n<h3 id=\"Dropout\">Dropout<a href=\"post/20200516-Neural-Networks#Dropout\"></a></h3><p><u><a href=\"https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5\" target=\"_blank\" rel=\"noopener\">More details from here</a></u>.</p>\n<p>In order to prevent over-fitting, we can use dropout to ignore units (i.e. neurons) during the training phase of certain set of neurons which is chosen at random so we can reduce interdependent learning amongst the neurons.</p>\n<div class=\"article-img\"><p><img src=\"https://i.loli.net/2020/06/25/hFOIB3paKbc1jmG.png\" alt=\"drop\" data-zoomable></p></div>\n<p>(from the paper”Dropout: a simple way to prevent neural networks from overfitting”, JMLR 2014)</p>\n<h3 id=\"Main-Steps\">Main Steps<a href=\"post/20200516-Neural-Networks#Main-Steps\"></a></h3><p>First, pick a network architecture.</p>\n<p>​    · Number of input units = dimension of features $x^{(i)}$</p>\n<p>​    · Number of output units = number of classes</p>\n<p>​    · Number of hidden units per layer = usually more the better (must balance with cost of computation as it increases with more hidden units)</p>\n<p>Next, training a Neural Network.</p>\n<p>​    · Randomly initialize the weights</p>\n<p>​    · Implement forward propagation to get $ h_\\Theta(x^{(i)}) $ for any $ x^{(i)} $</p>\n<p>​    · Implement the cost function</p>\n<p>​    · Implement backpropagation to compute partial derivatives</p>\n<p>​    · Use gradient checking to confirm that your backpropagation works. Then disable gradient checking.</p>\n<p>​    · Use gradient descent or a built-in optimization function to minimize the cost function with the weights in theta.</p>\n","prev":{"title":"Basic Model Selection and Evaluation","slug":"20200531-Model-Selection-and-Evaluation"},"next":{"title":"Basis & Regression & Classification","slug":"20200501-Machine-Learning-Basis"},"link":"https://oreodu.github.io/post/20200516-Neural-Networks/","toc":[{"title":"Neural Networks","id":"Neural-Networks","index":"1","children":[{"title":"Feed-Forward Neural network (Multilayer Perceptron)","id":"Feed-Forward-Neural-network-Multilayer-Perceptron","index":"1.1","children":[{"title":"Cost Function (regularized)","id":"Cost-Function-regularized","index":"1.1.1"},{"title":"Backpropagation Algorithm","id":"Backpropagation-Algorithm","index":"1.1.2"},{"title":"Gradient Checking","id":"Gradient-Checking","index":"1.1.3"},{"title":"Activation Function","id":"Activation-Function","index":"1.1.4"},{"title":"Optimization Function","id":"Optimization-Function","index":"1.1.5"},{"title":"Initialize the weights","id":"Initialize-the-weights","index":"1.1.6"},{"title":"Batch Normalization","id":"Batch-Normalization","index":"1.1.7"},{"title":"Dropout","id":"Dropout","index":"1.1.8"},{"title":"Main Steps","id":"Main-Steps","index":"1.1.9"}]}]}]}